--lr 0.0001 --new_lr 1e-5 --dec_hsz 128 --dropout 0.5 --rnn_layers 1 --batch_size 64 --epochs 50 --training_results logs/logs_0.0001_1e-5_128_0.5_1_64/training_results.txt --pretrain_actor_logs logs/logs_0.0001_1e-5_128_0.5_1_64/pretrain_actor_logs.txt --pretrain_critic_logs logs/logs_0.0001_1e-5_128_0.5_1_64/pretrain_critic_logs.txt --results_path results/resultsA2C_0.0001_1e-5_128_0.5_1_64 --actor_pretrained models/models_0.0001_1e-5_128_0.5_1_64/actor_pretrained.pth --critic_pretrained models/models_0.0001_1e-5_128_0.5_1_64/critic_pretrained.pth --actor_path models/models_0.0001_1e-5_128_0.5_1_64/actor.pth --critic_path models/models_0.0001_1e-5_128_0.5_1_64/critic.pth --enc_dec_path models/models_0.0001_1e-5_128_0.5_1_64/enc_dec.pth --final_results_path final_results/final_results_0.0001_1e-5_128_0.5_1_64 --train_logs logs/logs_0.0001_1e-5_128_0.5_1_64/actor_critic_train_logs.txt --train_reward_logs logs/logs_0.0001_1e-5_128_0.5_1_64/actor_critic_train_reward_logs.txt
